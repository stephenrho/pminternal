<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Get bias-corrected performance measures via bootstrapping or cross-validation — validate • pminternal</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Get bias-corrected performance measures via bootstrapping or cross-validation — validate"><meta name="description" content="Performs internal validation of a prediction model development procedure via bootstrapping
or cross-validation. Many model types are supported via the insight and marginaleffects
packages or users can supply user-defined functions that implement the model development
procedure and retrieve predictions. Bias-corrected scores and estimates of optimism (where applicable)
are provided. See confint.internal_validate for calculation of confidence intervals."><meta property="og:description" content="Performs internal validation of a prediction model development procedure via bootstrapping
or cross-validation. Many model types are supported via the insight and marginaleffects
packages or users can supply user-defined functions that implement the model development
procedure and retrieve predictions. Bias-corrected scores and estimates of optimism (where applicable)
are provided. See confint.internal_validate for calculation of confidence intervals."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">pminternal</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/pminternal.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/missing-data.html">Handling missing data</a></li>
    <li><a class="dropdown-item" href="../articles/validate-examples.html">More examples</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/stephenrho/pminternal/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Get bias-corrected performance measures via bootstrapping or cross-validation</h1>
      <small class="dont-index">Source: <a href="https://github.com/stephenrho/pminternal/blob/main/R/validate.R" class="external-link"><code>R/validate.R</code></a></small>
      <div class="d-none name"><code>validate.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Performs internal validation of a prediction model development procedure via bootstrapping
or cross-validation. Many model types are supported via the <code>insight</code> and <code>marginaleffects</code>
packages or users can supply user-defined functions that implement the model development
procedure and retrieve predictions. Bias-corrected scores and estimates of optimism (where applicable)
are provided. See <code><a href="confint.internal_validatesummary.html">confint.internal_validate</a></code> for calculation of confidence intervals.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">validate</span><span class="op">(</span></span>
<span>  <span class="va">fit</span>,</span>
<span>  method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"boot_optimism"</span>, <span class="st">"boot_simple"</span>, <span class="st">".632"</span>, <span class="st">"cv_optimism"</span>, <span class="st">"cv_average"</span>, <span class="st">"none"</span><span class="op">)</span>,</span>
<span>  <span class="va">data</span>,</span>
<span>  <span class="va">outcome</span>,</span>
<span>  <span class="va">model_fun</span>,</span>
<span>  <span class="va">pred_fun</span>,</span>
<span>  <span class="va">score_fun</span>,</span>
<span>  <span class="va">B</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-fit">fit<a class="anchor" aria-label="anchor" href="#arg-fit"></a></dt>
<dd><p>a model object. If fit is given the <code>insight</code> package is
used to extract data, outcome, and original model call. Therefore, it is important
that fit be supported by <code>insight</code> and implements the entire model development
process (see Harrell 2015). A fit given after selection of variables by some method will
not give accurate bias-correction. Model predictions are obtained via
<code><a href="https://marginaleffects.com/man/r/get_predict.html" class="external-link">marginaleffects::get_predict</a></code> with type = "response" so fit should be
compatible with this function. If fit is provided the arguments data, outcome,
model_fun, and pred_fun are all ignored.</p></dd>


<dt id="arg-method">method<a class="anchor" aria-label="anchor" href="#arg-method"></a></dt>
<dd><p>bias-correction method. Valid options are "boot_optimism", "boot_simple",
".632", "cv_optimism", "cv_average", or "none" (return apparent performance). See details.</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>a data.frame containing data used to fit development model</p></dd>


<dt id="arg-outcome">outcome<a class="anchor" aria-label="anchor" href="#arg-outcome"></a></dt>
<dd><p>character denoting the column name of the outcome in data</p></dd>


<dt id="arg-model-fun">model_fun<a class="anchor" aria-label="anchor" href="#arg-model-fun"></a></dt>
<dd><p>for models that cannot be supplied via fit this should be a function
that takes one named argument: 'data' (function should include ... among arguments).
This function should implement the entire model development
procedure (hyperparameter tuning, variable selection, imputation etc) and return an object
that can be used by pred_fun. Additional arguments can be supplied by ...</p></dd>


<dt id="arg-pred-fun">pred_fun<a class="anchor" aria-label="anchor" href="#arg-pred-fun"></a></dt>
<dd><p>for models that cannot be supplied via fit this should be a function
that takes two named arguments: 'model' and 'data' (function should include ... among arguments).
'model' is an object returned by model_fun.
The function should return a vector of predicted risk probabilities of the same length as the number
of rows in data. Additional arguments can be supplied by ...</p></dd>


<dt id="arg-score-fun">score_fun<a class="anchor" aria-label="anchor" href="#arg-score-fun"></a></dt>
<dd><p>function used to produce performance measures from predicted risks
and observed binary outcome. Should take two named arguments: 'y' and 'p' (function should include ... among arguments).
This function should return a named vector of scores. If unspecified <code><a href="score_binary.html">score_binary</a></code>
is used and this should be good for most purposes.</p></dd>


<dt id="arg-b">B<a class="anchor" aria-label="anchor" href="#arg-b"></a></dt>
<dd><p>number of bootstrap replicates or crossvalidation folds. If unspecified B is set to
200 for method = "boot_\*"/".632", or is set to 10 for method = "cv_\*".</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>additional arguments for user-defined functions. Arguments for
producing calibration curves can be set via 'calib_args' which should be
a named list (see <code><a href="cal_plot.html">cal_plot</a></code> and <code><a href="score_binary.html">score_binary</a></code>).
For method = "boot_optimism", "boot_simple", or ".632" users can specify a
<code>cores</code> argument (e.g., <code>cores = 4</code>) to run bootstrap samples in parallel.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>an object of class internal_validate containing apparent and bias-corrected
estimates of performance scores. If method = "boot_*" it also contains results pertaining
to stability of predictions across bootstrapped models (see Riley and Collins, 2023).</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Internal validation can provide bias-corrected estimates of performance (e.g., C-statistic/AUC)
for a model development procedure (i.e., expected performance if the same procedure were applied
to another sample of the same size from the same population; see references). There are several approaches to producing
bias-corrected estimates (see below). It is important that the fit or model_fun provided implement
the entire model development procedure, including any hyperparameter tuning and/or variable selection.</p>
<p>Note that <code>validate</code> does very little to check for missing values in predictors/features. If <code>fit</code> is
supplied <code><a href="https://easystats.github.io/insight/reference/get_data.html" class="external-link">insight::get_data</a></code> will extract the data used to fit the model and usually
this will result in complete cases being used. User-defined model and predict functions can
be specified to handle missing values among predictor variables. Currently any user supplied data will
have rows with missing outcome values removed.</p>
<p><b>method</b>
Different options for the method argument are described below:</p><dl><dt>boot_optimism</dt>
<dd><p>(default) estimates optimism for each score and subtracts from apparent score (score calculated
with the original/development model evaluated on the original sample). A new model is fit using the same procedure
using each bootstrap resample. Scores are calculated when applying the boot model to the boot sample (\(S_{boot}\))
and the original sample (\(S_{orig}\)) and the difference gives an estimate of optimism for a given resample (\(S_{boot} - S_{orig}\)).
The average optimism across the B resamples is subtracted from the apparent score to produce the bias corrected score.</p></dd>

<dt>boot_simple</dt>
<dd><p>implements the simple bootstrap. B bootstrap models are fit and evaluated on the original data.
The average score across the B replicates is the bias-corrected score.</p></dd>

<dt>.632</dt>
<dd><p>implements Harrell's adaption of Efron's .632 estimator for binary outcomes
(see rms::predab.resample and rms::validate). In this case the estimate of optimism is
\(0.632 \times (S_{app} - mean(S_{omit} \times w))\) where \(S_{app}\) is the apparent performance
score and \(S_{omit}\) is the score estimated using the bootstrap model evaluated on the out-of-sample
observations and \(w\) weights for the proportion of observations omitted (see Harrell 2015, p. 115).</p></dd>

<dt>cv_optimism</dt>
<dd><p>estimate optimism via B-fold crossvalidation. Optimism is the average of the difference
in performance measure between predictions made on the training vs test (held out fold) data. This is the approach
implemented in <code><a href="https://rdrr.io/pkg/rms/man/validate.html" class="external-link">rms::validate</a></code> with method="crossvalidation".</p></dd>

<dt>cv_average</dt>
<dd><p>bias corrected scores are the average of scores calculated by assessing the model developed on each
fold evaluated on the test/held out data. This approach is described and compared to "boot_optimism" and ".632" in
Steyerberg et al. (2001).</p></dd>

</dl><p><b>Calibration curves</b>
To make calibration curves and calculate the associated estimates (ICI, ECI, etc - see <code><a href="score_binary.html">score_binary</a></code>)
<code>validate</code> uses the default arguments in <code><a href="cal_defaults.html">cal_defaults</a></code>. These arguments are passed to the <code>pmcalibration</code> package
(see <code><a href="https://rdrr.io/pkg/pmcalibration/man/pmcalibration.html" class="external-link">?pmcalibration::pmcalibration</a></code> for options).</p>
<p>If a calibration plot (apparent vs bias corrected calibration curves via <code><a href="cal_plot.html">cal_plot</a></code>)
is desired, the argument 'eval' should be provided. This should be the points at which to evaluate
the calibration curve on each boot resample or crossvalidation fold. A good option would be
<code>calib_args = list(eval = seq(min(p), max(p), length.out=100))</code>; where p are predictions from the
original model evaluated on the original data.</p>
<p><b>Number of resamples/folds is less than requested</b>
If the <code>model_fun</code> produces an error or if <code>score_binary</code> is supplied with constant predictions
or outcomes (e.g. all(y == 0)) the returned scores will all be NA. These will be omitted from the calculation
of optimism or other bias-corrected estimates (cv_average, boot_simple) and the number of successful resamples/folds
will be &lt; B. <code>validate</code> collects errors and will produce a warning summarizing them. The number of successful
samples is given in the 'n' column in the printed summary of an 'internal_validate' object.</p>
<p>It is important to understand what is causing the loss of resamples/folds. Some potential sources (which will need to be added to) are that
for rare events the resamples/folds may be resulting in samples that have zero outcomes. For 'cv_*' this will especially
be the case if B (n folds) is set high. There may be problems with factor/binary predictor variables with rare levels, which could be dealt with
by specifying a <code>model_fun</code> that omits variables for the model formula if only one level is present. The issue may be related to the construction
of calibration curves and may be addressed by more carefully selecting settings (see section above).</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Steyerberg, E. W., Harrell Jr, F. E., Borsboom, G. J., Eijkemans, M. J. C., Vergouwe, Y., &amp; Habbema, J. D. F. (2001). Internal validation of predictive models: efficiency of some procedures for logistic regression analysis. Journal of clinical epidemiology, 54(8), 774-781.</p>
<p>Harrell Jr F. E. (2015). Regression Modeling Strategies: with applications to linear models, logistic and ordinal regression, and survival analysis. New York: Springer Science, LLC.</p>
<p>Efron (1983). “Estimating the error rate of a prediction rule: improvement on cross-validation”. Journal of the American Statistical Association, 78(382):316-331</p>
<p>Van Calster, B., Steyerberg, E. W., Wynants, L., and van Smeden, M. (2023). There is no such thing as a validated prediction model. BMC medicine, 21(1), 70.</p>
<p>Riley, R. D., &amp; Collins, G. S. (2023). Stability of clinical prediction models developed using statistical or machine learning methods. Biometrical Journal, 65(8), 2200302. doi:10.1002/bimj.202200302</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/stephenrho/pminternal" class="external-link">pminternal</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">456</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># simulate data with two predictors that interact</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu">pmcalibration</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pmcalibration/man/sim_dat.html" class="external-link">sim_dat</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fl">2000</span>, a1 <span class="op">=</span> <span class="op">-</span><span class="fl">2</span>, a3 <span class="op">=</span> <span class="op">-</span><span class="fl">.3</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 0.1985</span>
<span class="r-in"><span><span class="va">dat</span><span class="op">$</span><span class="va">LP</span> <span class="op">&lt;-</span> <span class="cn">NULL</span> <span class="co"># remove linear predictor</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># fit a (misspecified) logistic regression model</span></span></span>
<span class="r-in"><span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">dat</span>, family<span class="op">=</span><span class="st">"binomial"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># internal validation of m1 via bootstrap optimism with 10 resamples</span></span></span>
<span class="r-in"><span><span class="co"># B = 10 for example but should be &gt;= 200 in practice</span></span></span>
<span class="r-in"><span><span class="va">m1_iv</span> <span class="op">&lt;-</span> <span class="fu">validate</span><span class="op">(</span><span class="va">m1</span>, method<span class="op">=</span><span class="st">"boot_optimism"</span>, B<span class="op">=</span><span class="fl">10</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> It is recommended that B &gt;= 200 for bootstrap validation</span>
<span class="r-in"><span><span class="va">m1_iv</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>           apparent optimism corrected  n</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> C           0.7779  0.00158    0.7764 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Brier       0.1335 -0.00111    0.1346 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Intercept   0.0000 -0.01917    0.0192 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Slope       1.0000  0.00083    0.9992 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Eavg        0.0076  0.00516    0.0024 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> E50         0.0064  0.00381    0.0026 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> E90         0.0115  0.00882    0.0027 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Emax        0.0580  0.07771   -0.0197 10</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ECI         0.0110  0.03656   -0.0256 10</span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Stephen Rhodes.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

